
# Criar a fun√ß√£o Lambda `lambda_consumer_batch` (Consumer Batch)

Este guia cria a fun√ß√£o **Lambda** que consome eventos do **Kinesis Data Stream (`broker`)** e salva **dados brutos** no **Amazon S3**, **particionados por ano/m√™s/dia** no prefixo `raw/`.

---

## ‚úÖ Objetivo
- Receber registros do Kinesis (produzidos pelo *Producer*).
- Decodificar payload (Base64 ‚Üí UTF‚Äë8 ‚Üí JSON).
- Gravar o JSON **como est√°** (append‚Äëonly) em `s3://<bucket>/raw/<YYYY>/<MM>/<DD>/weather-data-<timestamp>.json`.

---

## üìã Pr√©‚Äërequisitos
- **Kinesis Data Stream** `broker` criado.
- **Bucket S3** criado com as pastas `raw/` e `gold/` (opcional para agora).
- **IAM Role** `Consumer-Batch` criada com as policies:
  - `AWSLambdaBasicExecutionRole`
  - `AmazonKinesisFullAccess`
  - `AmazonS3FullAccess`
- Fun√ß√£o **`Producer`** dispon√≠vel para gerar eventos de teste.

> üîê Em produ√ß√£o, substitua *FullAccess* por pol√≠ticas **de menor privil√©gio** espec√≠ficas para o stream e o bucket/prefixo.

---

## 1) Criar a fun√ß√£o Lambda
1. Acesse **AWS Lambda** ‚Üí **Create function**.
2. **Author from scratch**.
3. **Function name**: `lambda_consumer_batch`
4. **Runtime**: `Python 3.12`.
5. **Execution role** ‚Üí **Use an existing role** ‚Üí selecione **`Consumer-Batch`**.
6. Clique em **Create function**.

---

## 2) Adicionar o c√≥digo
1. Na aba **Code**, apague o exemplo inicial.
2. **Cole o c√≥digo** do *Consumer Batch* (do seu material do curso). O fluxo t√≠pico √©:
   - Ler `event["Records"]`.
   - `base64.b64decode(...)` ‚Üí `.decode("utf-8")` ‚Üí `json.loads(...)`.
   - Montar chave S3: `raw/<YYYY>/<MM>/<DD>/weather-data-<ISO_TIMESTAMP>.json`.
   - `s3_client.put_object(Bucket=<BUCKET>, Key=<KEY>, Body=json.dumps(data))`.
3. Clique em **Deploy** (obrigat√≥rio ao colar/editar o c√≥digo no editor).

> ‚ÑπÔ∏è As depend√™ncias usadas s√£o do runtime padr√£o (ex.: `boto3` j√° vem no AWS Lambda Python).

---

## 3) Vari√°veis de ambiente
1. V√° em **Configuration ‚Üí Environment variables** ‚Üí **Edit** ‚Üí **Add environment variable**.
2. Crie a vari√°vel do nome do bucket:
   - **Key**: `BUCKET_NAME` *(ou **exatamente** o nome que o seu c√≥digo espera; evite espa√ßos em nomes de vari√°veis)*
   - **Value**: o nome do seu bucket (ex.: `weather-rt`).
3. **Save**.

> O c√≥digo ler√° o nome do bucket desta vari√°vel e gravar√° sempre sob o prefixo `raw/` com parti√ß√£o por data.

---

## 4) Conectar o gatilho do Kinesis
1. Acesse **Configuration ‚Üí Triggers** ‚Üí **Add trigger**.
2. **Trigger**: `Kinesis`.
3. **Kinesis stream**: selecione **`broker`**.
4. Demais op√ß√µes: mantenha os **padr√µes**.
5. Clique em **Add**. O diagrama passar√° a mostrar o **Kinesis** como origem.

---

## 5) Testar de ponta a ponta
**Op√ß√£o A ‚Äì Producer manual**  
1. Abra a fun√ß√£o **`Producer`** ‚Üí **Test** (payload `{}`).
2. O Producer envia registros para `broker`, acionando `lambda_consumer_batch`.

**Op√ß√£o B ‚Äì Agendado (EventBridge)**  
1. Habilite o *schedule* que chama o **Producer** (1‚Äì3 min).

**Esperado no S3**  
- Em `s3://<bucket>/raw/<YYYY>/<MM>/<DD>/` devem surgir arquivos `weather-data-<timestamp>.json` (um por evento).

---

## 6) Validar no S3
1. Abra **S3 ‚Üí seu bucket ‚Üí raw/** e navegue por **ano/m√™s/dia**.
2. Baixe um arquivo e confira o JSON salvo **sem transforma√ß√µes**.

---

## 7) Dicas e solu√ß√£o de problemas
- **Nada chega ao S3**: verifique **CloudWatch Logs** da fun√ß√£o para erros, a vari√°vel `BUCKET_NAME` e a **Role** anexada.
- **Permiss√£o negada**: confirme pol√≠ticas da role (`s3:PutObject`, `kinesis:GetRecords`, etc.).
- **Muitas execu√ß√µes do Realtime**: desabilite temporariamente o *schedule* do Producer ou aumente os limiares do `Consumer-Realtime` para evitar envios de SNS durante seus testes.

---

## ‚úÖ Resultado
A fun√ß√£o **`lambda_consumer_batch`** est√° criada, assinando o **Kinesis `broker`** e persistindo **dados brutos particionados** no **S3** sob `raw/YYYY/MM/DD/`.
